# Reddit Content Research Agent

A lightweight agent designed to research and analyze Reddit content using LLMs, SERP APIs, and webhook-based background tasks. This project integrates **Bright Data SERP API**, **Google Gemini LLM**, **LangChain**, **Django**, **Celery**, and **Django-QStash** to automate content discovery, analysis, and asynchronous processing.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/                        # Stored data from scraped Reddit threads
â”œâ”€â”€ nbs/                         # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 01-Init.ipynb
â”‚   â”œâ”€â”€ 02-serp-api-init.ipynb
â”‚   â”œâ”€â”€ 03-google-gemini-llm-langchain.ipynb
â”‚   â”œâ”€â”€ ... (other notebooks)
â”‚   â””â”€â”€ setup.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ blog/                     # Django app for testing Celery & webhook tasks
â”‚   â”‚   â”œâ”€â”€ tasks.py              # Celery & QStash tasks
â”‚   â”‚   â”œâ”€â”€ views.py              # Webhook endpoints
â”‚   â”‚   â””â”€â”€ ... (other Django files)
â”‚   â”œâ”€â”€ ResearchAgent/            # Main Django project
â”‚   â”‚   â”œâ”€â”€ settings.py           # Includes QStash and Celery configs
â”‚   â”‚   â”œâ”€â”€ celery.py             # Celery configuration
â”‚   â”‚   â””â”€â”€ ... (other Django files)
â”‚   â””â”€â”€ manage.py
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .env.example                  # Template for environment variables
â”œâ”€â”€ compose.yaml                   # Docker-compose for Redis and other services
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ rav.yaml                       # Project scripts (runserver, ngrok, Celery, etc.)
â””â”€â”€ README.md
```

---

## ğŸš€ Features

* ğŸ” **Search Automation:** Uses Bright Data SERP API for search queries.
* ğŸ¤– **LLM Integration:** Google Gemini LLM with LangChain for intelligent responses.
* ğŸ§© **Tool Calling:** Demonstrates manual and automated LLM tool usage.
* ğŸ§± **Structured Output:** Pydantic for clean, validated data formats.
* âš¡ **Asynchronous Webhooks:** Django-QStash + Celery for reliable webhook processing.
* ğŸŒ **Local Testing:** Ngrok for exposing local Django server endpoints to the internet.

---

## ğŸ› ï¸ Installation

1. Clone the repository:

```bash
git clone https://github.com/your-username/Reddit-Content-Research-Agent.git
cd Reddit-Content-Research-Agent
```

2. Create a virtual environment and install dependencies:

```bash
python3 -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Configure environment variables (`.env`) including:

```
DJANGO_DEBUG=1
DJANGO_SECRET_KEY=<your_django_secret_key>
DATABASE_URL=postgres://pguser:pgpassword@localhost:5433/pgdb
REDIS_URL="redis://localhost:6380/0"
BRIGHT_DATA_SERP_API_KEY=<your_bright_data_key>
GOOGLE_GEMINI_API_KEY=<your_gemini_key>
QSTASH_TOKEN=<your_qstash_token>
CSRF_TRUSTED_ORIGINS=<ngrok_https_url>
ALLOWED_HOSTS=<ngrok_domain>
```

---

## â–¶ï¸ Usage

### 1. Jupyter Notebooks

```bash
rav run notebook
```

* Open notebooks in `nbs/` and run them step-by-step to validate API integrations and experiment with LLM tool calls.

### 2. Django & Celery

```bash
rav run runserver      # Start Django server on localhost:8000
rav run worker         # Start Celery worker for background tasks
```

* Make sure **Redis** is running:

```bash
rav run docker_up      # Start Redis via Docker
```

### 3. Ngrok for Webhooks

```bash
rav run ngrok          # Expose local server to the internet
```

* Copy the **HTTPS forwarding URL** and use it as your webhook endpoint (e.g., Stripe, Razorpay).
* Example webhook URL:

```
https://abcd-1234.ngrok-free.app/blog/webhook/
```

---

## ğŸ“Œ Webhook & Background Tasks

**Example Webhook Endpoint (`blog/views.py`):**

```python
from django.http import HttpResponse
from django_qstash.decorators import qstash_signed
from .tasks import process_payment_task

@qstash_signed
def stripe_webhook(request):
    process_payment_task.delay(request.json())
    return HttpResponse("Webhook received")
```

**Example Background Task (`blog/tasks.py`):**

```python
from celery import shared_task

@shared_task
def process_payment_task(data):
    print(f"Processing webhook data: {data}")
```

* `@qstash_signed` ensures that only QStash-sent requests are accepted.
* Celery handles heavy processing asynchronously so webhook returns immediately.

---

## ğŸ“Œ Notes

* Free-tier **ngrok URLs change every session** â†’ update `CSRF_TRUSTED_ORIGINS` and `ALLOWED_HOSTS`.
* QStash provides **reliable, signed delivery** of webhook tasks.
* Pre-commit hooks are included to maintain code formatting:

```bash
rav run clean
```